student_model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

# Option A: Use precomputed teacher outputs (preferred for offline)
teacher_outputs: "training_data/teacher_outputs.jsonl"

# Option B: (optional) live teacher calls if available
# teacher_model: "mistralai/Mixtral-8x7B-Instruct-v0.1"

lora:
  enabled: true
  r: 8
  alpha: 16
  dropout: 0.05

training:
  epochs: 1
  batch_size: 8
  lr: 2e-4
  max_len: 2048

data:
  adapter: jsonl
  path: training_data/core.jsonl

output_dir: "models/student-core-kd"
quantize: "int8"  # future step; export script to be added later
