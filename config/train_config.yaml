model_name_or_path: codellama/CodeLlama-7b-hf
train_file: training_data/reasoner/stage1_sample.jsonl
validation_file: training_data/reasoner/stage1_sample.jsonl
output_dir: outputs/checkpoints
lora_rank: 16
lora_alpha: 32
lora_target_modules:
  - q_proj
  - v_proj
train_batch_size: 4
eval_batch_size: 4
num_train_epochs: 1
learning_rate: 1e-4
mixed_precision: no
logging_steps: 10
save_steps: 50
evaluation_strategy: steps
eval_steps: 50
report_to: none
